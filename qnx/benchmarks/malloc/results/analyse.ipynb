{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites and Installation\n",
    "\n",
    "## Virtual Environment\n",
    "\n",
    "Ensure to have PIP installed. On Ubuntu:\n",
    "\n",
    "```sh\n",
    "apt install python3-pip\n",
    "```\n",
    "\n",
    "Create your virtual environment\n",
    "\n",
    "```sh\n",
    "python3 -m venv ./venv\n",
    "```\n",
    "\n",
    "Then once it's created, you need to initialise it before setting the Jupyter\n",
    "Kernel:\n",
    "\n",
    "```sh\n",
    ". ./venv/bin/activate\n",
    "```\n",
    "\n",
    "Choose the `venv` Python kernel from within VSCode. Follow instructions for\n",
    "installing the `ipykernel` which is needed to run Jupiter. It's installed safely\n",
    "in your virtual environment.\n",
    "\n",
    "If you can't see the `venv` as the kernel in VSCode, try changing to the\n",
    "directory where the `venv` folder is (not the `venv` folder itself, but one\n",
    "before it) and starting VSCode from there. Else you may unintentionally install\n",
    "all the packages needed in your global or user configuration.\n",
    "\n",
    "## Ubuntu Packages\n",
    "\n",
    "Install the following packages.\n",
    "\n",
    "- Allows exporting Jupyter notebooks as PDF:\n",
    "\n",
    "  ```sh\n",
    "  apt install texlive-xetex\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Tools\n",
    "\n",
    "Install the `matplotlib`, which will also install `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing Data\n",
    "\n",
    "You'll need to run the benchmark tests to capture the data. These files are\n",
    "stored in `.json` format.\n",
    "\n",
    "Under linux, Google Benchmark recommends to set the CPU governor to performance\n",
    "to avoid variations in running the benchmarks.\n",
    "\n",
    "```sh\n",
    "sudo cpupower frequency-set --governor performance\n",
    "```\n",
    "\n",
    "Under Linux, there is the script `run_linux.sh` which runs with various\n",
    "`mallopt()` options.\n",
    "\n",
    "## Running Benchmarks Manually\n",
    "\n",
    "Under Linux, you will want to run a command similar to the following:\n",
    "\n",
    "```sh\n",
    "export BASE_NAME=mymachine\n",
    "taskset -c 1 ./benchmarks/malloc/malloc_bench -mM_MMAP_THRESHOLD=0 --benchmark_out_format=json --benchmark_out=${BASE_NAME}_mmap.json\n",
    "```\n",
    "\n",
    "And further, you'd likely want to run multiple times with various different\n",
    "options for the `mallopt()` (by setting `-m` or setting environment variables as\n",
    "described by your system documentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data\n",
    "\n",
    "## Configuration File for What to Process\n",
    "\n",
    "Create a text file that is a collection of key/value pairs. Update the\n",
    "configuration file variable `CONFIG_FILE` to load what you need.\n",
    "\n",
    "This is a `.json` file that is a simple dictionary of a data-set name, and the\n",
    "google-benchmark `.json` output file with the test results.\n",
    "\n",
    "For example, [`i9-13950hx_Linux.json`](./i9-13950hx_Linux.json) contains a small\n",
    "JSON snippet, which is a dictionary of the data sets (the key is the name of the\n",
    "dataset that will be plotted later), and the file captured from the previous\n",
    "step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = \"rpi5_linux.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "if not os.path.isfile(CONFIG_FILE):\n",
    "    raise Exception(f\"File '{CONFIG_FILE}' not found\")\n",
    "\n",
    "with open(CONFIG_FILE, encoding=\"utf-8\") as config_file:\n",
    "    config_file_results = json.load(config_file)\n",
    "\n",
    "data = {}\n",
    "base_results_path = os.path.dirname(os.path.abspath(CONFIG_FILE))\n",
    "for test_run in config_file_results:\n",
    "    google_test_file = os.path.relpath(os.path.join(base_results_path, config_file_results[test_run]))\n",
    "    if os.path.exists(google_test_file):\n",
    "        if test_run in data:\n",
    "            raise Exception(f\"Test run {test_run} defined multiple times in {CONFIG_FILE}\")\n",
    "        data[test_run] = {}\n",
    "        data[test_run][\"file\"] = google_test_file\n",
    "        data[test_run][\"benchmark\"] = {}\n",
    "        data[test_run][\"results\"] = {}\n",
    "    else:\n",
    "        raise Exception(f\"Path {google_test_file} not found\")\n",
    "\n",
    "# Now the `data` variable can be enumerated by its keys to get the dataruns. We\n",
    "# don't need CONFIG_FILE any longer.\n",
    "#del CONFIG_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Internal Representation of Benchmark and Result Data in Python\n",
    "\n",
    "The data is organised in Python as a single variable. Values in angled quotes\n",
    "`<xx>` indicate a key name. It might be a string or an integer depending on the\n",
    "context. Note, some of the variables haven't been discussed yet, but the\n",
    "complete structure is defined here for a single reference when reading code.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"<test_run>\":  {\n",
    "        \"file\": \"<relative path>\",\n",
    "        \"benchmark\": {\n",
    "            \"<name>\": {\n",
    "                \"<size>\": {\n",
    "                    \"real_time\": \"<nanoseconds>\"\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"<size>\": {\n",
    "                \"t_Tm\": \"<value>\",   // Total Malloc/Free\n",
    "                \"t_m\": \"<value>\",    // Malloc\n",
    "                \"t_fm\": \"<value>\",   // Free\n",
    "                \"t_Tc\": \"<value>\",   // Total Calloc/Free\n",
    "                \"t_c\": \"<value>\",    // Calloc\n",
    "                \"t_fc\": \"<value>\",   // Free\n",
    "                \"t_wm\": \"<value>\",   // Walk Time (Malloc/Free)\n",
    "                \"t_wc\": \"<value>\"    // Walk Time (Malloc/MemSet/Free)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Each \"`<test_run>`\" is loaded from a `.json` file referenced by the\n",
    "`CONFIG_FILE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for test_run in data.keys():\n",
    "    with open(data[test_run][\"file\"], encoding=\"utf-8\") as google_result:\n",
    "        google_data = json.load(google_result)\n",
    "\n",
    "    # Parse through the file, extracting the contents and putting it into the\n",
    "    # new dictionary.\n",
    "    for benchmark in google_data[\"benchmarks\"]:\n",
    "        match = re.search(\"BM_(\\S+)/(\\d+)\", benchmark[\"name\"])\n",
    "        if match is not None:\n",
    "            malloc_name = match.group(1)\n",
    "            malloc_size = int(match.group(2))\n",
    "            realtime = benchmark[\"real_time\"]\n",
    "\n",
    "            if malloc_name not in data[test_run][\"benchmark\"]:\n",
    "                data[test_run][\"benchmark\"][malloc_name] = {}\n",
    "            if malloc_size not in data[test_run][\"benchmark\"][malloc_name]:\n",
    "                data[test_run][\"benchmark\"][malloc_name][malloc_size] = {}\n",
    "            data[test_run][\"benchmark\"][malloc_name][malloc_size][\"real_time\"] = realtime\n",
    "\n",
    "#print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Times for `malloc()`/clear/`free()`\n",
    "\n",
    "We calculate the data for each \"`<test_run>`\", and they're independent of each\n",
    "other for this type of graph. The \"`<name>`\" is the name of the benchmark, and\n",
    "these benchmarks are referred to each other within a test to estimate metrics.\n",
    "\n",
    "### Calculating the Time for `malloc()` and `free()` (and `calloc()`)\n",
    "\n",
    "Google Benchmark runs by executing contents in a loop multiple times, and then\n",
    "estimating the average time for each loop run. This means that a `malloc()` may\n",
    "run a large number of times, such that if run too often, the benchmark will\n",
    "crash due to out of memory. So the loop must necessarily be followed by a\n",
    "`free()` call that the loop can be run an arbitrary number of times.\n",
    "\n",
    "Hence the test `BM_MallocFreeBenchmark` executes a `malloc()` followed by a\n",
    "`free()` and the measurement is the average time of _both_.\n",
    "\n",
    "To estimate the time required in just the `malloc()` call and just the `free()`\n",
    "call, we must run benchmarks that use the Google Benchmark function\n",
    "`PauseTiming()` and `ResumeTiming()`. This introduces overhead, such that:\n",
    "\n",
    "Let:\n",
    "\n",
    "\\begin{align}\n",
    "T_{MallocBench} &= T_M + T_P\n",
    "\\end{align}\n",
    "\n",
    "and:\n",
    "\n",
    "\\begin{align}\n",
    "T_{FreeBench} &= T_F + T_P\n",
    "\\end{align}\n",
    "\n",
    "So that $T_M$ is the actual time for the `malloc()` call, and $T_F$ is the time\n",
    "for the `free()` call. The overhead $T_P$ is due to the `PauseTiming()` and\n",
    "`ResumeTiming()` overhead, which for very fast function calls (of the order of\n",
    "up to 1000ns for $T_M$ or $T_F$ makes a reasonable influence).\n",
    "\n",
    "Then we know we've measured:\n",
    "\n",
    "\\begin{align}\n",
    "T_{MallocFreeBench} &= T_M + T_F \\\\\n",
    "T_{MallocFreeBench} &= T_{MallocBench} + T_{FreeBench} + 2 T_P\n",
    "\\end{align}\n",
    "\n",
    "So given all three measurements, we can calculate what the overhead is, and\n",
    "calculate the true value of $T_M$ and $T_F$ which is what we want to plot:\n",
    "\n",
    "\\begin{align}\n",
    "T_P &= \\frac{1}{2} \\left( T_{MallocFreeBench} - T_{MallocBench} - T_{FreeBench} \\right)\n",
    "\\end{align}\n",
    "\n",
    "so that:\n",
    "\n",
    "\\begin{align}\n",
    "T_M &= \\frac{1}{2} \\left( T_{MallocFreeBench} + T_{MallocBench} - T_{FreeBench} \\right) \\\\\n",
    "T_F &= \\frac{1}{2} \\left( T_{MallocFreeBench} - T_{MallocBench} + T_{FreeBench} \\right)\n",
    "\\end{align}\n",
    "\n",
    "Similarly, the same equations can be used for the `calloc()` call to estimate the sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to Calculate from the Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_run in data:\n",
    "    # Get the sizes used for each benchmark. They should be consistent.\n",
    "    sizes = []\n",
    "    for benchmark in data[test_run][\"benchmark\"]:\n",
    "        for size in data[test_run][\"benchmark\"][benchmark]:\n",
    "            if size not in sizes:\n",
    "                sizes.append(size)\n",
    "\n",
    "    for size in sizes:\n",
    "        mallocfree_time = data[test_run][\"benchmark\"][\"MallocFreeBench\"][size][\"real_time\"]\n",
    "        malloc_time = data[test_run][\"benchmark\"][\"MallocBench\"][size][\"real_time\"]\n",
    "        mfree_time = data[test_run][\"benchmark\"][\"MFreeBench\"][size][\"real_time\"]\n",
    "        t_m = 0.5 * (mallocfree_time + malloc_time - mfree_time)\n",
    "        t_fm = 0.5 * (mallocfree_time - malloc_time + mfree_time)\n",
    "\n",
    "        callocfree_time = data[test_run][\"benchmark\"][\"CallocFreeBench\"][size][\"real_time\"]\n",
    "        calloc_time = data[test_run][\"benchmark\"][\"CallocBench\"][size][\"real_time\"]\n",
    "        cfree_time = data[test_run][\"benchmark\"][\"CFreeBench\"][size][\"real_time\"]\n",
    "        t_c = 0.5 * (callocfree_time + calloc_time - cfree_time)\n",
    "        t_fc = 0.5 * (callocfree_time - calloc_time + cfree_time)\n",
    "\n",
    "        mallocwalk_time = data[test_run][\"benchmark\"][\"MallocWalkFreeBench\"][size][\"real_time\"]\n",
    "        t_wm = mallocwalk_time - mallocfree_time\n",
    "\n",
    "        mallocset_time = data[test_run][\"benchmark\"][\"MallocClearFreeBench\"][size][\"real_time\"]\n",
    "        mallocsetwalk_time = data[test_run][\"benchmark\"][\"MallocClearWalkFreeBench\"][size][\"real_time\"]\n",
    "        t_wc = mallocsetwalk_time - mallocset_time\n",
    "\n",
    "        if size not in data[test_run][\"results\"]:\n",
    "            data[test_run][\"results\"][size] = {}\n",
    "        data[test_run][\"results\"][size][\"t_Tm\"] = mallocfree_time\n",
    "        data[test_run][\"results\"][size][\"t_m\"] = t_m\n",
    "        data[test_run][\"results\"][size][\"t_fm\"] = t_fm\n",
    "        data[test_run][\"results\"][size][\"t_Tc\"] = callocfree_time\n",
    "        data[test_run][\"results\"][size][\"t_c\"] = t_c\n",
    "        data[test_run][\"results\"][size][\"t_fc\"] = t_fc\n",
    "        data[test_run][\"results\"][size][\"t_wm\"] = t_wm\n",
    "        data[test_run][\"results\"][size][\"t_wc\"] = t_wc\n",
    "\n",
    "#print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Histograms of `malloc()` and `free()`\n",
    "\n",
    "Now we can collect the data, process it so it can be graphed. `MatPlotLib` is\n",
    "used to prepare the axis and draw the histograms that can be exported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preamble Code for Setting up the Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_size(unit):\n",
    "    match unit:\n",
    "        case 0:\n",
    "            return \"\"\n",
    "        case 1:\n",
    "            return \"k\"\n",
    "        case 2:\n",
    "            return \"M\"\n",
    "        case 3:\n",
    "            return \"G\"\n",
    "        case _:\n",
    "            return \"?\"\n",
    "\n",
    "def auto_size(size):\n",
    "    unit=0\n",
    "    while size >= 1024:\n",
    "        unit += 1\n",
    "        size = size / 1024\n",
    "\n",
    "    return f\"{int(size)} {unit_size(unit)}B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "############################################################\n",
    "# Prepare the data to be easily plotted\n",
    "# - strsizes are the labels. It's not scaled on the x-axis.\n",
    "# - malloc_perf is the \"total\" time\n",
    "# - malloc_perf_m is the time to do just the alloc.\n",
    "\n",
    "sizes = []\n",
    "for test_run in data:\n",
    "    # Get the sizes used for each benchmark. They should be consistent.\n",
    "    for benchmark in data[test_run][\"benchmark\"]:\n",
    "        for size in data[test_run][\"benchmark\"][benchmark]:\n",
    "            if size not in sizes:\n",
    "                sizes.append(size)\n",
    "sizes = sorted(sizes)\n",
    "\n",
    "strsizes = []\n",
    "for size in sizes:\n",
    "    #strsizes.append(str(int(size / 1024)))\n",
    "    strsizes.append(auto_size(size))\n",
    "strsizes = np.array(strsizes)\n",
    "\n",
    "############################################################\n",
    "# Graph the data\n",
    "\n",
    "set_colors = [\n",
    "    \"#1f78b4\", \"#33a02c\", \"#e31a1c\", \"#ff7f00\",\n",
    "    \"#6a3d9a\", \"#b15928\", \"#a6cee3\", \"#b2df8a\",\n",
    "    \"#fb9a99\", \"#fdbf6f\", \"#cab2d6\", \"#ffff99\",\n",
    "]\n",
    "\n",
    "def plot_malloc_benchmarks(title, strsizes, perf_malloc_free, perf_malloc, time_log_scale):\n",
    "    x = np.arange(len(strsizes))   # Label locations\n",
    "    width = 1 / (len(perf_malloc_free) + 1)    # We have \"test_runs\" bars per size\n",
    "\n",
    "    fig, ax = plt.subplots(facecolor=\"lightgrey\", figsize=(8,4), dpi=300)\n",
    "\n",
    "    # The first plot is the total time for the operation.\n",
    "    multiplier = 0\n",
    "    for attribute, measurement in perf_malloc_free.items():\n",
    "        offset = width * multiplier\n",
    "        # - x is an array [0, 1, 2, ..., len(sizes)-1 ]\n",
    "        # - offset shifts the plot exactly by one bar width, so each dataset appears\n",
    "        #   side by side, looking like a histogram.\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute, color=set_colors[multiplier])\n",
    "        multiplier += 1\n",
    "\n",
    "    # The second plot overlays the \"malloc\" time with an alpha that makes it a bit\n",
    "    # darker, se we can see how much time it takes to do an allocation.\n",
    "\n",
    "    if perf_malloc is not None:\n",
    "        multiplier = 0\n",
    "        for attribute, measurement in perf_malloc.items():\n",
    "            offset = width * multiplier\n",
    "            # - x is an array [0, 1, 2, ..., len(sizes)-1 ]\n",
    "            # - offset shifts the plot exactly by one bar width, so each dataset appears\n",
    "            #   side by side, looking like a histogram.\n",
    "            rects = ax.bar(x + offset, measurement, width, color=\"#001020\", alpha=0.5)\n",
    "            multiplier += 1\n",
    "\n",
    "    plt.rc(\"legend\", fontsize=5)\n",
    "    ax.grid(visible=True, which=\"major\", axis=\"both\")\n",
    "    ax.grid(visible=True, which=\"minor\", axis=\"y\")\n",
    "    ax.set_title(f\"{title} - {CONFIG_FILE}\")\n",
    "    ax.set_xlabel(\"Size\")\n",
    "    ax.set_xticks(x + (1-width)/2, strsizes)          # `(1-width)/2` aligns to the centre\n",
    "    ax.set_xticklabels(strsizes, rotation=90)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", grid_color=\"lightgrey\", grid_linewidth=0.5, grid_linestyle=\"dashed\")\n",
    "    ax.tick_params(axis=\"y\", which=\"minor\", grid_color=\"lightgrey\", grid_linewidth=0.5, grid_linestyle=\"dashed\")\n",
    "    if time_log_scale:\n",
    "        ax.set_ylabel(\"Log_Time (µs)\\n(Darker is 'alloc' time)\")\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.minorticks_on()\n",
    "        ax.yaxis.set_major_locator(ticker.LogLocator(numticks=20))\n",
    "        ax.yaxis.get_minor_locator().set_params(numticks=20, subs=[.2, .4, .6, .8])\n",
    "    else:\n",
    "        ax.set_ylabel(\"Time (µs)\\n(Darker is 'alloc' time)\")\n",
    "        ax.yaxis.set_minor_locator(ticker.AutoMinorLocator(10))\n",
    "        ax.tick_params(axis=\"y\", which=\"minor\", grid_color=\"lightgrey\", grid_linewidth=0.5, grid_linestyle=\"dashed\")\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.legend(loc=\"upper left\")  # ncols=len(data)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of `malloc()` Speed\n",
    "\n",
    "The `malloc()` function call returns data that is uninitialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key is the test run, the value is an array of results in the order by sizes.\n",
    "malloc_perf = {}\n",
    "for test_run in data:\n",
    "    malloc_perf[test_run] = []\n",
    "    for size in sizes:\n",
    "        malloc_perf[test_run].append(data[test_run][\"results\"][size][\"t_Tm\"] / 1000)\n",
    "malloc_perf_m = {}\n",
    "for test_run in data:\n",
    "    malloc_perf_m[test_run] = []\n",
    "    for size in sizes:\n",
    "        malloc_perf_m[test_run].append(data[test_run][\"results\"][size][\"t_m\"] / 1000)\n",
    "\n",
    "LOG=True\n",
    "if not LOG:\n",
    "    plot_malloc_benchmarks(\"malloc() speed\", strsizes, malloc_perf, malloc_perf_m, LOG)\n",
    "else:\n",
    "    # WARNING: Plotting the two graphs on a logarithmic scale will cause\n",
    "    # observers to read incorrectly the distorted data. If the `malloc()` and\n",
    "    # the `free()` are the same amount of time, the user will think that the\n",
    "    # `malloc()` (the darker graph) is significantly more time (which it isn't).\n",
    "    plot_malloc_benchmarks(\"malloc()/free() speed (Logarithmic Scale)\", strsizes, malloc_perf, malloc_perf_m, LOG)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of `calloc()` Speed\n",
    "\n",
    "The `calloc()` function call returns data that, when read, should return zero bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calloc_perf = {}\n",
    "for test_run in data:\n",
    "    calloc_perf[test_run] = []\n",
    "    for size in sizes:\n",
    "        calloc_perf[test_run].append(data[test_run][\"results\"][size][\"t_Tc\"] / 1000)\n",
    "calloc_perf_m = {}\n",
    "for test_run in data:\n",
    "    calloc_perf_m[test_run] = []\n",
    "    for size in sizes:\n",
    "        calloc_perf_m[test_run].append(data[test_run][\"results\"][size][\"t_c\"] / 1000)\n",
    "\n",
    "plot_malloc_benchmarks(\"calloc() speed\", strsizes, calloc_perf_m, None, True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walking Allocated Memory\n",
    "\n",
    "The results given from the `malloc()` benchmarks and the `calloc()` benchmarks\n",
    "may be returning memory very fast. Indeed, some of the data appears to be so\n",
    "fast, it appears that the Operating System may not allocate the pages, and only\n",
    "map it to the Operating System.\n",
    "\n",
    "The hypotheses can be tested by walking each page returned. We know that an\n",
    "Operating System must allocate a minimum of one page (this is the smallest size\n",
    "of memory that the CPU MMU can manage, mapping a virtual address to a physical\n",
    "address).\n",
    "\n",
    "Often Operating Systems do *lazy* page allocation. They indicate to the MMU that\n",
    "the page belongs to the process, but they do not allocate a physical page from\n",
    "system memory to the process. This is done only when the process accesses the\n",
    "memory (either read or write).\n",
    "\n",
    "i.e.\n",
    "\n",
    "- A process allocates 1GB of RAM\n",
    "- The libc implementation of `malloc()` does a `mmap()` call, requesting 1GB of\n",
    "  RAM.\n",
    "- The Operating System updates the MMU for the current process running, by\n",
    "  creating MMU Page Tables, enough for 1GB. On most Operating Systems with 4kB\n",
    "  pages, this is then 262,144 pages, which map a continuous region of virtual\n",
    "  memory (visible by the process).\n",
    "- In *Lazy* locking, the page tables are all created in the MMU, but no pages\n",
    "  from physical memory are allocated.\n",
    "  - When virtual memory addresses are accessed that result in a page that is not\n",
    "    yet allocated, a page fault occurs, and the Operating System will find an\n",
    "    available page, resident in memory (and if the contents are in swap, it is\n",
    "    copied from disk back to memory), and control is given back to the process\n",
    "    without it knowing (only taking time).\n",
    "  - With systems that have no swap, this has the effect that memory allocations\n",
    "    usually always pass, but a crash of the program may occur at any time if\n",
    "    there is no pages available.\n",
    "- In *Super* locking, the pages are allocated from the free page pool\n",
    "  immediately. This takes more time, but we know we will never get the page\n",
    "  fault and memory accesses are fast. We know our process won't crash from out\n",
    "  of memory accesses.\n",
    "\n",
    "Thus three tests are performed that help to guage if the memory is allocated in\n",
    "physical memory or not:\n",
    "\n",
    "- BM_MallocWalkFreeBench\n",
    "- BM_MallocClearFreeBench\n",
    "- BM_MallocClearWalkFreeBench\n",
    "\n",
    "The difference between the `BM_MallocWalkFreeBench` and the `BM_MallocFreeBench`\n",
    "is that after memory is allocated, the value of `0` is written to the first byte\n",
    "of every page. Note, we don't every byte, as then the results would be very much\n",
    "dependent on the memory bandwidth of the system. Writing only a single byte we\n",
    "easily measure the performance overhead if the Operating System must handle a\n",
    "page fault and allocate that to the process.\n",
    "\n",
    "Similarly, we can see if any optimisation tricks are done when clearing memory\n",
    "with the `memset(p, 0, SIZE)` call, by looking at the difference between\n",
    "`BM_MallocClearWalkFreeBench` and `BM_MallocClearFreeBench`.\n",
    "\n",
    "So now:\n",
    "\n",
    "\\begin{align}\n",
    "T_{MallocFreeBench} &= T_M &&&+ T_F \\\\\n",
    "T_{MallocWalkFreeBench} &= T_M &&+ T_W &+ T_F \\\\\n",
    "T_{MallocClearFreeBench} &= T_M &+ T_C &&+ T_F \\\\\n",
    "T_{MallocClearWalkFreeBench} &= T_M &+ T_C &+ T_W &+ T_F \\\\\n",
    "\\end{align}\n",
    "\n",
    "Plot the difference between the equations to get the $T_W$ walk time, and if the\n",
    "values are significant, then it indicates overhead due to page faults. Some\n",
    "overhead will be present due to the loops, but this is expected to be smaller\n",
    "than the time required for a page fault.\n",
    "\n",
    "where:\n",
    "\n",
    "- $T_M$ is the call to `malloc()` as earlier.\n",
    "- $T_C$ is the call to `memset(p, 0, size)`. We should be able to see if this\n",
    "  causes a lot of time.\n",
    "  - It appears there are optimisations that even the `memset()` is fast, without\n",
    "    requiring physical pages to be allocated.\n",
    "- $T_W$ is the time for the first access. If memory was not actually allocated\n",
    "  by the `malloc()` or `memset()` call, this is expected to take a measurable\n",
    "  amount of time. Else the access will be very fast and effectively zero.\n",
    "- $T_F$ ist he call to `free()` as earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_perf = {}\n",
    "for test_run in data:\n",
    "    walk_perf[test_run] = []\n",
    "    for size in sizes:\n",
    "        walk_perf[test_run].append(data[test_run][\"results\"][size][\"t_wm\"] / 1000)\n",
    "\n",
    "plot_malloc_benchmarks(\"walk after malloc() speed\", strsizes, walk_perf, None, True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memsetwalk_perf = {}\n",
    "for test_run in data:\n",
    "    memsetwalk_perf[test_run] = []\n",
    "    for size in sizes:\n",
    "        memsetwalk_perf[test_run].append(data[test_run][\"results\"][size][\"t_wc\"] / 1000)\n",
    "\n",
    "plot_malloc_benchmarks(\"walk after malloc()/memset() speed\", strsizes, memsetwalk_perf, None, True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
